#!/usr/bin/env python3

import sys, argparse, os, asyncio, shutil, urllib3, requests, concurrent
from collections import namedtuple
from packaging import version
from blinky.package_tree import Package, dedup_pkgs
from blinky import pacman, utils

parser = argparse.ArgumentParser(description="AUR package management made easy")
primary = parser.add_mutually_exclusive_group()
primary.add_argument("--version", action='store_true', default=False, dest='print_version', help="print version info and exit")
primary.add_argument("-S", action='store_true', default=False, dest='install', help="Install package(s) from AUR")
primary.add_argument("-Sr", action='store_true', default=False, dest='rebuildpkg', help="Reinstall package(s) from AUR (including rebuild)")
primary.add_argument("-Srr", action='store_true', default=False, dest='rebuildtree', help="Reinstall package(s) and dependencies from AUR (including rebuild)")
primary.add_argument("-Ss", action='store_true', default=False, dest='search', help="Search for package(s) in AUR")
parser.add_argument("--by", action='store', default=None, dest='search_by', metavar='<value>', help="search specifically by field")
primary.add_argument("-complete", action='store_true', default=False, dest='complete', help=argparse.SUPPRESS)
primary.add_argument("-Si", action='store_true', default=False, dest='info', help="Get detailed info on packages in AUR")
primary.add_argument("-Syu", action='store_true', default=False, dest='upgrade', help="Upgrade all out-of-date AUR-packages")
primary.add_argument("-Sc", action='store_true', default=False, dest='clean', help="Clean cache of all uninstalled package files")
primary.add_argument("-Scc", action='store_true', default=False, dest='fullclean', help="Clean cache of all package files, including installed")
primary.add_argument("--rebuild-python-from-aur", action='store_true', default=False, dest='rebuild_aur_python', help="Rebuild all installed 'python-*' packages that originate in the AUR")
parser.add_argument("--asdeps", action='store_true', default=False, dest='asdeps', help="If packages are installed, install them as dependencies")
parser.add_argument("--force-review", action='store_true', default=False, dest='force_review', help="Force review even if exact copies of the files have already been reviewed positively")
parser.add_argument("--keep-builddeps", action='store_true', default=False, dest='keep_builddeps', help="Do not uninstall previously uninstalled makedeps after building")
parser.add_argument("--keep-sources", action='store', default='none', dest='keep_sources', metavar='<value>', help="Keep sources, can be 'none' (default), 'skipped', for keeping skipped packages only, or 'all'")
parser.add_argument("--build-only", action='store_true', default=False, dest='buildonly', help="Only build, do not install anything")
parser.add_argument("pkg_candidates", metavar="pkgname", type=str, nargs="*", help="packages to install/build")
parser.add_argument('--verbose', '-v', action='count', default=0, dest='verbosity')
parser.add_argument("--ignore-ood", action='store_true', default=False, dest='ignore_ood', help="Ignore packages flagged out-ot-date")
parser.add_argument("--no-ignore-ood", action='store_true', default=False, dest='no_ignore_ood', help="Negates --ignore-ood")
parser.add_argument("--difftool", action='store', default=None, dest='difftool', metavar='<difftool>', help="specify tool used for diffing (must work via '<tool> file1 file2')")
parser.add_argument("--makepkg.conf", action='store', default='/etc/makepkg.conf', dest='makepkgconf', metavar='makepkg-configfile', help="Configuration file for makepkg, defaults to /etc/makepkg.conf")
parser.add_argument("--ignore", action='append', default=[], dest='ignored_pkgs', metavar='<pkg>', help="ignore package (can be specified multiple times)")
parser.add_argument("-n", "--notify", action='store_true', default=False, dest='notify_on_interaction', help="Ignore packages flagged out-ot-date")
parser.add_argument("--print-error-log-lines", action='store', type=int, default=0, dest='printed_error_log_lines', help="In case of build-errors, print up to this many lines of stderr right to stdout (default: 0, -1 for entire stderr)")

args = parser.parse_args()

if len(sys.argv) < 2:
	# if no arguments are supplied, print help message and exit
	parser.print_help()
	sys.exit()

Config = namedtuple('Context', ['cachedir', 'builddir', 'revieweddir', 'logdir', 'force_review', 'rebuild', 'difftool', 'makepkgconf', 'ignored_pkgs', 'v', 'ignore_ood', "printed_error_log_lines"])

verified_makepkgconf = '/etc/makepkg.conf'
if os.path.isfile(args.makepkgconf) and os.access(args.makepkgconf, os.R_OK):
	verified_makepkgconf = args.makepkgconf
else:
	utils.logerr(None, "{} not found, using /etc/makepkg.conf instead".format(args.makepkgconf))

ctx = Config(
		cachedir=os.path.join(utils.get_cache_dir(), 'pkg'),
		builddir=os.path.join(utils.get_cache_dir(), 'build'),
		logdir=os.path.join(utils.get_cache_dir(), 'logs'),
		revieweddir=os.path.join(utils.get_data_dir(), 'reviewed'),
		force_review=args.force_review,
		rebuild='package' if (args.rebuildpkg or args.rebuild_aur_python) else 'tree' if args.rebuildtree else None,
		difftool=args.difftool,
		makepkgconf=verified_makepkgconf,
		ignored_pkgs=args.ignored_pkgs,
		v=args.verbosity,
		ignore_ood = args.ignore_ood if not args.no_ignore_ood else False,
		printed_error_log_lines = args.printed_error_log_lines
		)

os.makedirs(ctx.cachedir, exist_ok=True)
os.makedirs(ctx.builddir, exist_ok=True)
os.makedirs(ctx.logdir, exist_ok=True)
os.makedirs(ctx.revieweddir, exist_ok=True)

utils.logmsg(ctx.v, 2, ("builddir: {}".format(ctx.builddir)))
utils.logmsg(ctx.v, 2, ("cachedir: {}".format(ctx.cachedir)))
utils.logmsg(ctx.v, 2, ("makepkg-logdir: {}".format(ctx.logdir)))
utils.logmsg(ctx.v, 2, ("dir for reviewed files: {}".format(ctx.revieweddir)))

if args.buildonly:
	utils.logmsg(ctx.v, 0, "Sources can be found at {}".format(ctx.builddir))


def cleanup_procedure(pkgs, pkgs_skipped, keep_sources):
	if not keep_sources == "all":
		for p in pkgs:
			p.remove_sources()

	if not keep_sources in ["all", "skipped"]:
		for p in pkgs_skipped:
			p.remove_sources()


unneeded_makedeps = set()

def cleanup_makedeps():
	global unneeded_makedeps
	if unneeded_makedeps and not args.keep_builddeps:
		utils.logmsg(ctx.v, 0, "Removing previously uninstalled makedeps")
		pacman.refresh()
		if not pacman.remove_packages([p.name for p in unneeded_makedeps if pacman.find_local_satisfier(p.name)]):
			utils.logerr(None, "Failed to remove previously uninstalled makedeps")


def build_packages_from_aur(package_candidates, install_as_dep=False):
	aurpkgs, repopkgs, notfoundpkgs, aurdata = utils.check_in_aur(package_candidates)

	if repopkgs:
		utils.logmsg(ctx.v, 1, "Skipping: {}: packaged in repos".format(", ".join(repopkgs)))
	if notfoundpkgs:
		utils.logmsg(ctx.v, 1, "Skipping: {}: neither in repos nor AUR".format(", ".join(notfoundpkgs)))

	packages = []
	skipped_packages = set()
	if len(aurpkgs) == 0:
		utils.logmsg(ctx.v, 0, "No package candidates found in AUR, nothing to do.")
		exit(0)
	else:
		utils.logmsg(ctx.v, 0, "Fetching information and files for dependency-graph for {} package{}".format(len(aurpkgs), '' if len(aurpkgs) == 1 else 's'))


	def parse_packages_with_depcheck(pkgname, ctx=None):
		try:
			return Package(pkgname, ctx=ctx)
		except utils.UnsatisfiableDependencyError as e:
			utils.logerr(None, "Cannot build {}: {}".format(pkgname, str(e)))
			return None

	with concurrent.futures.ThreadPoolExecutor(max_workers=10) as e:
		pkg_parsers = []
		for p in aurpkgs:
			pkg_parsers.append(e.submit(parse_packages_with_depcheck, p, ctx))

		try:
			packages = [pkg_parser.result() for pkg_parser in pkg_parsers if pkg_parser.result()]
		except Exception as e:
			utils.logerr(8, e.args[0].reason)


	dedup_pkgs(ctx)

	for p in packages:
		p.get_src()

	if args.notify_on_interaction:
		utils.display_notification("User interaction required:\nreview")
	for p in packages:
		if not p.review():
			utils.logmsg(ctx.v, 0, "Skipping: {}: Did not pass review".format(p.name))
			skipped_packages.add(p)

	# drop all packages that did not pass review
	for p in skipped_packages:
		packages.remove(p)

	skipped_packages = set()

	# check for dependencies and drop everything whose dependencies cannot be met upfront
	skipped_due_to_missing_deps = set()

	# first we do makedeps
	# then we do deps, as deps can implicitly also be makedeps and therefore have to be built/installed beforehand
	uninstalled_makedeps = set()
	uninstalled_deps     = set()
	for pkg in packages:
		md = pkg.get_makedeps()
		md_not_found         = [p for p in md if not p.installed and not p.in_repos and not p.in_aur]
		uninstalled_makedeps = uninstalled_makedeps.union(set([p for p in md if not p.installed and (p.in_repos or p.in_aur is not None)]))
		if len(md_not_found) > 0:
			msg = "{}: cannot satisfy makedeps from either repos, AUR or local installed packages, skipping"
			utils.logerr(None, msg.format(pkg.name))
			skipped_packages.add(pkg)
			skipped_due_to_missing_deps.add(pkg)

	uninstalled_deps = set()
	for pkg in packages:
		d = pkg.get_deps()
		d_not_found      = [p for p in d if not p.installed and not p.in_repos and not p.in_aur]
		uninstalled_deps = uninstalled_deps.union(set([p for p in d if not p.installed and (p.in_repos or p.in_aur)]))
		if len(d_not_found) > 0:
			msg = "{}: cannot satisfy deps from either repos, AUR or local installed packages, skipping"
			utils.logerr(None, msg.format(pkg.name))
			skipped_packages.add(pkg)
			skipped_due_to_missing_deps.add(pkg)

	# drop all packages whose makedeps cannot be satisfied
	for p in skipped_due_to_missing_deps:
		packages.remove(p)

	deps_aur     = set([p for p in uninstalled_deps if p.in_aur])
	makedeps_aur = set([p for p in uninstalled_makedeps if p.in_aur])
	deps_aur_total = deps_aur.union(makedeps_aur)
	if len(deps_aur_total) > 0:
		pacman.refresh()
		utils.logmsg(ctx.v, 0, "Building deps from aur: {}".format(", ".join(p.name for p in deps_aur_total)))
		build_packages_from_aur([p.name for p in deps_aur_total], install_as_dep=True)

	repodeps = set()
	for p in packages:
		repodeps = repodeps.union(p.get_repodeps())

	md_repos = set([p.name for p in uninstalled_makedeps if p.in_repos])
	repodeps_uninstalled = set([p.name for p in repodeps if not p.installed])
	to_be_installed = repodeps_uninstalled.union(md_repos)

	if args.notify_on_interaction:
		utils.display_notification("User interaction required:\npackage installation")
	if to_be_installed:
		utils.logmsg(ctx.v, 0, "Installing dependencies from repos")
		if not pacman.install_repo_packages(to_be_installed, asdeps=True):
			utils.logerr(0, "Could not install dependencies from repos")


	pacman.refresh()
	skipped_due_to_makedep_not_installed = []
	for p in packages:
		if not p.check_makedeps_installed():
			skipped_due_to_makedep_not_installed.append(p)
			utils.logerr(None, "Skipping {}: not all required makedeps installed".format(p.name))

	for p in skipped_due_to_makedep_not_installed:
		packages.remove(p)


	for p in packages:
		success = p.build(buildflags=['-Cfd'], recursive=True)
		if success:
			od = p.get_optdeps()
			for name, optdeplist in od:
				print(" :: Package {} has optional dependencies:".format(p.name))
				for odname in optdeplist:
					s = pacman.find_local_satisfier(odname)
					if s and s.name == odname:
						print("     - {} (installed)".format(odname))
					elif s:
						print("     - {} (installed (via {}))".format(odname, s.name))
					else:
						print("     - {}".format(odname))

	built_pkgs = set()
	built_deps = set()
	for p in packages:
		built_pkgs = built_pkgs.union(set(p.built_pkgs))
		for d in p.deps:
			built_deps = built_deps.union(d.get_built_pkgs())

	os.chdir(ctx.cachedir)

	if args.buildonly:
		utils.logmsg(ctx.v, 1, "Packages have been built:")
		utils.logmsg(ctx.v, 1, ", ".join(built_deps.union(built_pkgs)) or "None")
	else:
		if args.notify_on_interaction:
			utils.display_notification("User interaction required:\ninstallation of built packages")

		if built_deps:
			utils.logmsg(ctx.v, 0, "Installing package dependencies")
			if not pacman.install_package_files(built_deps, asdeps=True):
				cleanup_procedure(packages, skipped_packages, args.keep_sources)
				utils.logerr(2, "Failed to install built package dependencies")

		if built_pkgs:
			utils.logmsg(ctx.v, 0, "Installing built packages")
			if not pacman.install_package_files(built_pkgs, asdeps=install_as_dep):
				cleanup_procedure(packages, skipped_packages, args.keep_sources)
				utils.logerr(2, "Failed to install built packages")
		else:
			utils.logmsg(ctx.v, 0, "No packages built, nothing to install")

	if uninstalled_makedeps:
		global unneeded_makedeps
		unneeded_makedeps = unneeded_makedeps.union(uninstalled_makedeps)

	cleanup_procedure(packages, skipped_packages, args.keep_sources)



def clean_cache(keep_installed=False):

	def get_pkgname_with_meta(fname):
		try:
			*pkgnameparts, pkgver, pkgrel, pkgarch = fname.split(".pkg.")[0].split("-")
		except ValueError:
			msg = "Non-package {} detected in {}. You might want to clean this up manually.".format(fname, ctx.cachedir)
			utils.logerr(None, msg)
			raise

		name = "-".join(pkgnameparts)
		version = "{}-{}".format(pkgver, pkgrel)
		return name, version

	def get_installed_prefixes(cachedir):
		installed_prefixes = []
		pkgs = os.listdir(cachedir)
		pkgnames = {}
		for p in pkgs:
			try:
				name, version = get_pkgname_with_meta(p)
				if name not in pkgnames:
					pkgnames[name] = []
				pkgnames[name].append(version)
			except ValueError:
				continue


		for name, versions in pkgnames.items():
			s = pacman.find_local_satisfier(name)
			for v in versions:
				if not s:
					continue

				installed_pkg_prefix = "{}-{}-x86_64.pkg.".format(name, s.version)
				this_pkg_prefix      = "{}-{}-x86_64.pkg.".format(name, v)

				if installed_pkg_prefix == this_pkg_prefix:
					installed_prefixes.append(this_pkg_prefix)

		return installed_prefixes

	def isin(single, listing):
		for l in listing:
			if single.startswith(l):
				return True
		return False

	prefixes_to_keep = [] if not keep_installed else get_installed_prefixes(ctx.cachedir)
	os.chdir(ctx.cachedir)
	pkgs = os.listdir(ctx.cachedir)
	for p in pkgs:
		if isin(p, prefixes_to_keep):
			continue
		else:
			os.remove(p)


def clean_builddir():
	os.chdir(ctx.builddir)
	try:
		for pkgdir in os.listdir(ctx.builddir):
			shutil.rmtree(pkgdir, onerror=lambda f, p, e: utils.delete_onerror(f, p, e))
	except PermissionError:
		utils.logerr(None, "Cannot remove {}: Permission denied".format(self.srcdir))





if __name__ == "__main__":
	try:
		if args.install or args.rebuildpkg or args.rebuildtree:
			utils.exit_if_root()
			build_packages_from_aur(args.pkg_candidates, install_as_dep=args.asdeps)
			cleanup_makedeps()
		if args.complete:
			aurdata = utils.query_aur("search", args.pkg_candidates, ignore_ood=ctx.ignore_ood)
			import re
			exp = re.compile(args.pkg_candidates[0] + '.*')
			for pkgdata in aurdata["results"]:
				if exp.match(pkgdata["Name"]):
					print(pkgdata["Name"])
		if args.search:
			from termcolor import colored

			valid_by_values = ["name", "name-desc", "maintainer", "depends", "makedepends", "optdepends", "checkdepends"]
			if args.search_by and args.search_by not in valid_by_values:
				util.logerr(1, "specified field is to search by is not available, must be one of {}".format(", ".join(valid_by_values)))

			aurdata = utils.query_aur_exit_on_error("search", args.pkg_candidates, search_by=args.search_by, ignore_ood=ctx.ignore_ood)
			if not aurdata or aurdata["resultcount"] == 0:
				utils.logmsg(ctx.v, 0, "No results found")
			else:
				for pkgdata in aurdata["results"]:

					crepo = colored('aur/', color='magenta', attrs=['bold'])
					cname = colored(pkgdata["Name"], attrs=['bold'])
					cversion = colored(pkgdata["Version"], color='green', attrs=['bold'])

					installed_state = ""
					if pacman.find_local_satisfier(pkgdata["Name"]):
						installed_state = colored("[installed]", color='cyan', attrs=['bold'])

					print("{}{} {} {}".format(crepo, cname, cversion, installed_state))

					desc = pkgdata["Description"]
					print("    " + (desc if desc else colored("no description provided by PKGBUILD", color='white')))

		if args.info:
			from blinky.templates import pkginfo
			foundSth = False
			for pkg in args.pkg_candidates:
				pkgdata = utils.query_aur_exit_on_error("info", pkg, single=True, ignore_ood=ctx.ignore_ood)
				if pkgdata:
					foundSth = True
					print(pkginfo.format(
							name=pkgdata.get("Name"),
							version=pkgdata.get("Version"),
							desc=pkgdata.get("Description"),
							url=pkgdata.get("URL"),
							license=", ".join(pkgdata.get("License") or ["None"]),
							groups=", ".join(pkgdata.get("Groups") or ["None"]),
							provides=", ".join(pkgdata.get("Provides") or ["None"]),
							deps=", ".join(pkgdata.get("Depends") or ["None"]),
							optdeps=", ".join(pkgdata.get("OptDepends") or ["None"]),
							makedeps=", ".join(pkgdata.get("MakeDepends") or ["None"]),
							conflicts=", ".join(pkgdata.get("Conflicts") or ["None"]),
							replaces=", ".join(pkgdata.get("Replaces") or ["None"]),
							maintainer=pkgdata.get("Maintainer"),
							submitted=pkgdata.get("FirstSubmitted"),
							numvotes=pkgdata.get("NumVotes"),
							popularity=pkgdata.get("Popularity"),
							outofdate=pkgdata.get("OutOfDate") or "No"
							))

			if not foundSth:
				utils.logmsg(ctx.v, 0, "No results found")

		if args.upgrade:
			utils.exit_if_root()

			utils.logmsg(ctx.v, 0, "Checking for updates against AUR")
			foreign_pkg_v = pacman.get_foreign_package_versions()
			aurdata = utils.query_aur_exit_on_error("info", foreign_pkg_v.keys(), ignore_ood=ctx.ignore_ood)
			upgradable_pkgs = []
			for pkgdata in aurdata["results"]:
				if pkgdata["Name"] in foreign_pkg_v:
					v_upstream = version.parse(pkgdata["Version"])
					v_installed = version.parse(foreign_pkg_v[pkgdata["Name"]])
					if v_upstream > v_installed:
						upgradable_pkgs.append(pkgdata["Name"])

			build_packages_from_aur(upgradable_pkgs)
			cleanup_makedeps()
		if args.rebuild_aur_python:
			utils.exit_if_root()

			pypkgs = [pkg for pkg in pacman.ldb.pkgcache if pkg.name.startswith("python-")]
			python_pkgs_from_aur = [pkg for pkg in pypkgs if not pacman.find_satisfier_in_syncdbs(pkg.name)]
			pkgnames = [pkg.name for pkg in python_pkgs_from_aur]

			build_packages_from_aur(pkgnames)
			cleanup_makedeps()

		if args.clean:
			clean_cache(keep_installed=True)
			clean_builddir()
		if args.fullclean:
			clean_cache(keep_installed=False)
			clean_builddir()
		if args.print_version:
			print("0.22.1")

	except urllib3.exceptions.MaxRetryError as e:
		msg = "Unable to connect to {}: Max retries exceeded".format(e.url)
		utils.logerr(1, msg)
	except requests.exceptions.ConnectTimeout as e:
		basepath = e.request.url.split('?')[0]
		msg = "Unable to connect to {}: Connection timeout".format(basepath)
	except requests.exceptions.ConnectionError as e:
		basepath = e.request.url.split('?')[0]
		msg = "Unable to connect to {}: Reason unclear".format(basepath)

